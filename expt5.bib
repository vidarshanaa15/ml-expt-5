@article{zhang2019adam,
  title={Why ADAM Beats SGD for Attention Models},
  author={Zhang, J. and Karimireddy, S.P. and Veit, A. and Kim, S. and Reddi, S.J. and Kumar, S. and Sra, S.},
  year={2019}
}

@inproceedings{uzair2020hidden,
  author    = {Uzair, M. and Jamil, N.},
  title     = {Effects of Hidden Layers on the Efficiency of Neural Networks},
  booktitle = {2020 IEEE 23rd International Multitopic Conference (INMIC)},
  year      = {2020},
  pages     = {1--6},
  publisher = {IEEE}
}

@article{srivastava2014dropout,
  author  = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  volume  = {15},
  number  = {1},
  pages   = {1929--1958},
  year    = {2014}
}

@article{santos2022regularization,
  author  = {Santos, C. F. G. D. and Papa, J. P.},
  title   = {Avoiding Overfitting: A Survey on Regularization Methods for Convolutional Neural Networks},
  journal = {ACM Computing Surveys (CSUR)},
  volume  = {54},
  number  = {10s},
  pages   = {1--25},
  year    = {2022}
}
